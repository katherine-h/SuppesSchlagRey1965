I study rule-based concept learning. A classic study in this area is Suppes and Schlag-Rey's “Observable changes of hypotheses under positive reinforcement” (1965), which shows that people frequently revise their hypotheses about the definition of a concept even in response to evidence indicating that their hypothesis is already consistent with the data. This supports a model in which people continually update a probabilistic picture of a set of rule hypotheses and the corresponding data classifications.

During the initial phase of this experiment, the authors asked participants to classify letter patterns (e.g. “DDK”, “DKK”, etc. — all triples composed of D’s and K's, written on white index cards) into two categories ("blue" and "pink"). The authors did not give participants any hints as to the true bases of the categories, which were governed by a rule (that pink items are patterns ending with "DD" or "KK"). During the second phase of the experiment, in each of a series of trials, the experimenter removed one of the white index cards and gave the participant a blue or pink card containing the same pattern of letters; the color of the card indicated to which category that pattern belonged. Having been given this positive reinforcement (the true category matched the participant's initial category guess) or negative reinforcement, the participant had an opportunity to move around any cards they thought they had misclassified during the initial sorting phase. One would predict that participants would re-classify cards in light of negative reinforcement. However, they often did so even given positive reinforcement, which is mysterious because the new evidence in this case would merely seem to validate their existing hypothesis about what the rule is. These findings, then, suggest a number of interesting questions about the nature of rule-based concept learning, and so seem worthwhile to replicate.

I will conduct a replication study on Amazon's Mechanical Turk. Stimuli will consist of virtual cards specified in JavaScript, containing patterns of letters consistent with the rule used in the original study. During the initial phase of the experiment, participants will click on a card pile to reveal a card, then drag and drop the card into one of two category "bins" (sections of the screen, labeled "blue" and "pink"). During the second phase, in a given trial, a pink or blue card will appear on the left-hand side of the screen. The participant will place it in the correct category bin, and then move the white card containing the same pattern of letters from whichever bin it appears in to a trash can (thus forcing the participant to attend to whether their original classification was correct). Next, the participant will have the option to reclassify as many cards as they wish, using the drag-and-drop interface. Trials will end once all of the original white cards have been replaced. In addition to the original experiment, I will add two tasks at the beginning of the session, to ensure that participants are competent to perform the experiment: (A) a color identification task to test that the participant can distinguish between the card colors, and (B) a task in which the participant practices dragging and dropping a (blank) card from one section of the screen to another.

One worry about an MTurk replication is that participants may not be motivated to reclassify cards, wishing instead to complete the experiment as quickly as possible, and thus skipping this crucial step. A challenge, then, will be coming up with a way to encourage participants to actively participate during the trials, without unduly incentivizing moving cards whenever possible, given that no-move is an important option in the experiment.